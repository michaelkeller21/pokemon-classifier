{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am most interested in the work of the connectionists and neural networks. In this report, I will attempt to answer the following question:\n",
    "\n",
    "Given an image of a Pokemon, can a convolutional neural network model be used to classify the Pokemon by type?\n",
    "\n",
    "I had this inspiration from a dataset I recently found on Kaggle, shown here:\n",
    "\n",
    "https://www.kaggle.com/vishalsubbiah/pokemon-images-and-types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I refer the reader to the following Wikipedia article for more information on Pokemon:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Pok%C3%A9mon_(video_game_series)\n",
    "\n",
    "For the purposes of context for this report, Pokemon is shorthand for Pocket Monsters, and it is a Japanese video game series developed for Nintendo gaming systems. In it, the player goes on an adventure where they assemble a team of 6 creatures, train them up to become strong, and compete for the recognition of becoming the most powerful trainer in the game world. Players in Pokemon compete by battling them against each other. As of this writing, there are 890 unique Pokemon. The Kaggle dataset mentioned above contains only 809 Pokemon, and was not updated for the additional 81 Pokemon introduced in Pokemon Sword and Shield in November 2019.\n",
    "\n",
    "Each Pokemon has a primary and possibly a secondary type. For the purposes of complexity, we will only use the primary type of a Pokemon as a class label. There are 18 unique types of Pokemon, which each type having its own strengths and weaknesses in battle with respect to other types. Examples of types include Fire, Water, Grass, Ground, or Electric. We will investigate in this report the ability of a CNN to distinguish Pokemon by type based on their appearance in images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/mkell/Downloads/pokemon-images-and-types')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['Bug', 'Dark', 'Dragon', 'Electric', 'Fairy', 'Fighting', 'Fire',\n",
      "       'Flying', 'Ghost', 'Grass', 'Ground', 'Ice', 'Normal', 'Poison',\n",
      "       'Psychic', 'Rock', 'Steel', 'Water'], dtype=object), array([ 72,  29,  27,  40,  18,  29,  53,   3,  27,  78,  32,  23, 105,\n",
      "        34,  53,  46,  26, 114], dtype=int64))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Type1</th>\n",
       "      <th>Type2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abomasnow</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Ice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abra</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>absol</td>\n",
       "      <td>Dark</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accelgor</td>\n",
       "      <td>Bug</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aegislash-blade</td>\n",
       "      <td>Steel</td>\n",
       "      <td>Ghost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>zoroark</td>\n",
       "      <td>Dark</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>zorua</td>\n",
       "      <td>Dark</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>zubat</td>\n",
       "      <td>Poison</td>\n",
       "      <td>Flying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>zweilous</td>\n",
       "      <td>Dark</td>\n",
       "      <td>Dragon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>zygarde-50</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>Ground</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>809 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name    Type1   Type2\n",
       "0          abomasnow    Grass     Ice\n",
       "1               abra  Psychic     NaN\n",
       "2              absol     Dark     NaN\n",
       "3           accelgor      Bug     NaN\n",
       "4    aegislash-blade    Steel   Ghost\n",
       "..               ...      ...     ...\n",
       "804          zoroark     Dark     NaN\n",
       "805            zorua     Dark     NaN\n",
       "806            zubat   Poison  Flying\n",
       "807         zweilous     Dark  Dragon\n",
       "808       zygarde-50   Dragon  Ground\n",
       "\n",
       "[809 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokemon=pd.read_csv('pokemon.csv')\n",
    "print(np.unique(pokemon['Type1'], return_counts=True))\n",
    "pokemon=pokemon.sort_values('Name')\n",
    "pokemon=pokemon.reset_index(drop=True)\n",
    "pokemon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the original dataset of 809 Pokemon. We will use the column 'Type1' for labeling. Next we load in the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=np.empty((len(os.listdir('images/images')), 120, 120, 3))\n",
    "count=0\n",
    "\n",
    "for root, dirs, files in os.walk('images'):\n",
    "    for i, file in enumerate(files):        \n",
    "        path = os.path.join(root, file) \n",
    "        img=cv2.imread(path)        \n",
    "        images[count] = img        \n",
    "        count=count+1\n",
    "        #print(\"Loaded file \"+str(count)+ \" of \"+str(len(os.listdir('images/images')))+ \" \")              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(809, 120, 120, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Pokemon types are intuitive and some are not. For example, the first and third Pokemon in the original dataset are Ice-type Pokemon, which is supported by their white, snowy appearance. However, the second Pokemon is Psychic-type, which is not immediately evident from its appearance. The difficulty of this task for humans is present because of this fact. Thus, we hope to see how difficult this task is for a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the original dataset contains only 809 images in 18 classes. This is hardly enough data with which to train a model. Nevertheless, we will try and train a model on this small dataset to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/mkell/Dropbox/Spring 2020/Artificial Intelligence/pokemon-type-classifier/pokemon-classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we preprocess the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create labels\n",
    "image_labels=np.array(pokemon['Type1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize data\n",
    "images/=255\n",
    "images=images.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "image_labels = label_encoder.fit_transform(image_labels)\n",
    "# one hot encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "image_labels = image_labels.reshape(len(image_labels), 1)\n",
    "image_labels = onehot_encoder.fit_transform(image_labels)\n",
    "image_labels = np.asarray(image_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train/test sets\n",
    "train_data, test_data, train_labels, test_labels=train_test_split(images, image_labels, test_size=0.3, shuffle=True)\n",
    "train_data, val_data, train_labels, val_labels=train_test_split(train_data, train_labels, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the model. Our input images are of size (120, 120, 3), as they are 120x120 RGB images. We use a Conv-Pool-Conv-Pool format for the network, doubling the number of filters in each convolutional layer. Once we have reduced the output to 512 1x1 images, we flatten the convolutional output, we use 3 Dense layers at the end of the network with 256, 128, and 64 nodes before pssing the output to our final softmax layer of 18 classes. All layers of the neural network except the final output layer have a Rectified Linear Unit, or ReLU activation function.\n",
    "\n",
    "These choices for model architecture were based on past convolutional neural network designs in the field. For an optimizer, we use Adam, or adaptive gradient descent with momentum. This is the most widely accepted optimizer for convolutional neural networks in the literature. We use a learning rate of 0.0001 for the network. This was determined through trial and error of training the network. We train the network with 63% of the 809 Pokemon, validate it on 7% of the 809 Pokemon, and test it on 30% of the 809 Pokemon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 116, 116, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 58, 58, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 56, 56, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 128)       204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 3, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 18)                1170      \n",
      "=================================================================\n",
      "Total params: 1,874,834\n",
      "Trainable params: 1,874,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(5, 5), activation='relu', input_shape=(120, 120, 3)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(18, activation='softmax'))\n",
    "\n",
    "adam=tf.keras.optimizers.Adam(lr=10**-4)\n",
    "\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc=tf.keras.callbacks.ModelCheckpoint('best_pokemon_model.hdf5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "hist=model.fit(train_data, train_labels, batch_size=1, epochs=50, verbose=1, callbacks=[mc], \n",
    "               validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.4113418594799905, 0.23045267]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=tf.keras.models.load_model('best_pokemon_model.hdf5')\n",
    "test_results=model.evaluate(test_data, test_labels, verbose=0)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we have 18 classes of Pokemon type, if a network were randomly guessing, it would achieve an accuracy of 1/18=0.055. Achieving a test accuracy of 23% thus means the network is doing better than randomly guessing, though still has fairly low accuracy. This supports the conclusion that there are noticeable, yet inconsistent patterns in Pokemon appearance that signify type.\n",
    "\n",
    "There is also the possibility that a dataset of 809 instances is two small to properly train a model. It is possible to artificially inflate the dataset by making copies of the existing images or making rotated or reflected copies of the images. However, this will likely lead to overfitting, and it will be difficult to generalize what the network has learned to new Pokemon when they are released, as there is a large amount of variety in Pokemon design. Future work will investigate how rotations or reflections of these images affect the network. However, these initial findings will conclude the first draft of this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/vishalsubbiah/pokemon-images-and-types\n",
    "    \n",
    "https://en.wikipedia.org/wiki/Pok%C3%A9mon_(video_game_series)\n",
    "\n",
    "https://towardsdatascience.com/a-guide-to-an-efficient-way-to-build-neural-network-architectures-part-ii-hyper-parameter-42efca01e5d7\n",
    "\n",
    "https://www.youtube.com/watch?v=g2vlqhefADk&t=273s\n",
    "\n",
    "https://www.pyimagesearch.com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
